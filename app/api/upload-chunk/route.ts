import { NextResponse } from 'next/server';
import { createWriteStream, promises as fsPromises, existsSync, mkdirSync, unlinkSync, createReadStream } from 'fs';
import { join } from 'path';
import { tmpdir } from 'os';
import { pipeline } from 'stream';
import { promisify } from 'util';
import { getUniqueFilename } from './getUniqueFilename';
import { Storage } from '@google-cloud/storage';

const pump = promisify(pipeline);
const { writeFile } = fsPromises;

let googleCloudCredentials;
// è§£ç¢¼ base64 ç·¨ç¢¼çš„ GOOGLE_CLOUD_CREDENTIALS ç’°å¢ƒè®Šæ•¸
try {
    // è§£ç¢¼ä¸¦è§£æ GOOGLE_CLOUD_CREDENTIALS
    const credentialsBase64 = process.env.GOOGLE_CLOUD_CREDENTIALS!;
    const decodedCredentials = Buffer.from(credentialsBase64, 'base64').toString('utf-8');

    // ç¢ºä¿è§£ç¢¼å¾Œçš„å…§å®¹æ˜¯æœ‰æ•ˆçš„ JSON
    googleCloudCredentials = JSON.parse(decodedCredentials);

} catch (error) {
    console.error("Failed to parse Google Cloud credentials:", error);
}
// å‰µå»º Storage å¯¦ä¾‹ï¼Œä½¿ç”¨å·²è§£æçš„ credentials å’Œ projectId
const storage = new Storage({
    projectId: process.env.GOOGLE_CLOUD_PROJECT_ID,
    credentials: googleCloudCredentials,  // ä½¿ç”¨è§£æå¾Œçš„ JSON ä½œç‚º credentials
});

// console.log(googleCloudCredentials,"===========googleCloudCredentialsğŸ˜ğŸ˜ğŸ˜")

const bucketName = process.env.GOOGLE_CLOUD_BUCKET_NAME || '';
const bucket = storage.bucket(bucketName);

export const runtime = 'nodejs';

export async function POST(req: Request) {
    try {
        const formData = await req.formData();

        const files = formData.getAll('file') as Blob[];
        const filenames = formData.getAll('filename') as string[];
        const chunkIndexes = formData.getAll('chunkIndex') as string[];
        const totalChunksArray = formData.getAll('totalChunks') as string[];

        if (files.length === 0 || filenames.length === 0 || chunkIndexes.length === 0 || totalChunksArray.length === 0) {
            throw new Error('Missing file or metadata');
        }

        for (let i = 0; i < files.length; i++) {
            const file = files[i];
            const originalFilename = filenames[i];
            const chunkIndex = chunkIndexes[i];
            const totalChunks = totalChunksArray[i];

            // å‰µå»ºä¸€å€‹æœ¬åœ°çš„è³‡æ–™å¤¾uploads
            // const uploadDir = join(process.cwd(), 'uploads');
            // if (!existsSync(uploadDir)) {
            //     mkdirSync(uploadDir, { recursive: true });
            // }

            const uploadDir = join(tmpdir(), 'uploads');  // ä½¿ç”¨è‡¨æ™‚ç›®éŒ„
            if (!existsSync(uploadDir)) {
                mkdirSync(uploadDir, { recursive: true });
            }

            const uniqueFilename = getUniqueFilename(uploadDir, originalFilename);

            const tempDir = join(tmpdir(), 'chunks');
            try {
                if (!existsSync(tempDir)) {
                    mkdirSync(tempDir, { recursive: true });
                }
            } catch (err) {
                console.error('Failed to create temp directory:', err);
                throw err;
            }

            const tempFilePath = join(tempDir, `${uniqueFilename}.part${chunkIndex}`);
            console.log(`Saving chunk at: ${tempFilePath}`);
            try {
                if (!existsSync(tempFilePath)) {
                    const buffer = Buffer.from(await file.arrayBuffer());
                    await writeFile(tempFilePath, buffer);
                    console.log(`Received chunk ${Number(chunkIndex) + 1}/${totalChunks} for file ${uniqueFilename}`);
                } else {
                    console.log(`Chunk ${chunkIndex} already exists for file ${uniqueFilename}, skipping upload.`);
                }
            } catch (error) {
                console.error(`Failed to write chunk ${chunkIndex} for file ${uniqueFilename}:`, error);
                throw error;
            }

            const allChunksExist = (totalChunks: number, uniqueFilename: string, tempDir: string) => {
                for (let i = 0; i < totalChunks; i++) {
                    const chunkFilePath = join(tempDir, `${uniqueFilename}.part${i}`);
                    if (!existsSync(chunkFilePath)) {
                        return false;  // å¦‚æœä»»ä½•ä¸€å€‹åˆ†ç‰‡ç¼ºå¤±ï¼Œè¿”å› false
                    }
                }
                return true;  // æ‰€æœ‰åˆ†ç‰‡éƒ½å­˜åœ¨ï¼Œè¿”å› true
            };

            // åˆä½µä¸¦ä¸Šå‚³ä¹‹å‰æª¢æŸ¥æ‰€æœ‰åˆ†ç‰‡æ˜¯å¦å­˜åœ¨
            if (parseInt(chunkIndex) + 1 === parseInt(totalChunks)) {
                // æª¢æŸ¥æ‰€æœ‰åˆ†ç‰‡æ˜¯å¦å­˜åœ¨
                const allChunksPresent = allChunksExist(parseInt(totalChunks), uniqueFilename, tempDir);

                if (!allChunksPresent) {
                    console.error(`Some chunks are missing for file ${uniqueFilename}, cannot merge.`);
                    return NextResponse.json({ error: 'Missing chunks, cannot merge' }, { status: 400 });
                }

                const completeFilePath = join(uploadDir, uniqueFilename);
                const writeStream = createWriteStream(completeFilePath);

                try {
                    await new Promise<void>((resolve, reject) => {
                        writeStream.on('finish', resolve);
                        writeStream.on('error', reject);

                        (async () => {
                            for (let j = 0; j < parseInt(totalChunks); j++) {
                                const chunkFilePath = join(tempDir, `${uniqueFilename}.part${j}`);

                                const readStream = createReadStream(chunkFilePath);
                                try {
                                    await pump(readStream, writeStream);
                                    unlinkSync(chunkFilePath); // åˆªé™¤å·²åˆä½µçš„åˆ†ç‰‡
                                } catch (error) {
                                    console.error(`Error merging chunk ${j}:`, error);
                                    reject(error);
                                    return;
                                }
                            }
                            writeStream.end(); // ç¢ºä¿çµæŸ
                        })();
                    });

                    console.log(`File upload complete for ${uniqueFilename}`);

                    // ä¸Šå‚³åˆä½µå¾Œçš„æ–‡ä»¶åˆ° Google Cloud Storage
                    const destination = `uploads/${uniqueFilename}`;
                    await bucket.upload(completeFilePath, {
                        destination,
                        resumable: false,
                        gzip: true,
                    });

                    // åˆªé™¤æœ¬åœ°è‡¨æ™‚æ–‡ä»¶
                    await fsPromises.unlink(completeFilePath);

                    const publicUrl = `https://storage.googleapis.com/${bucketName}/${destination}`;
                    console.log(`File successfully uploaded to ${publicUrl}`);

                } catch (error) {
                    console.error(`Failed to merge and upload chunks for file ${uniqueFilename}:`, error);
                    throw error;
                }
            }
        }

        return NextResponse.json({ message: 'Files uploaded successfully' });
    } catch (error) {
        console.error(error);
        return NextResponse.json({ error: 'Failed to upload file chunks' }, { status: 500 });
    }
}
